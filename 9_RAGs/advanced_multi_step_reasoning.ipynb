{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887ba97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema  import Document\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edad96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Peak Performance Gym was founded in 2015 by former Olympic athlete Marcus Chen. With over 15 years of experience in professional athletics, Marcus established the gym to provide personalized fitness solutions for people of all levels. The gym spans 10,000 square feet and features state-of-the-art equipment.\",\n",
    "        metadata={\"source\": \"about.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Peak Performance Gym is open Monday through Friday from 5:00 AM to 11:00 PM. On weekends, our hours are 7:00 AM to 9:00 PM. We remain closed on major national holidays. Members with Premium access can enter using their key cards 24/7, including holidays.\",\n",
    "        metadata={\"source\": \"hours.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Our membership plans include: Basic (₹1,500/month) with access to gym floor and basic equipment; Standard (₹2,500/month) adds group classes and locker facilities; Premium (₹4,000/month) includes 24/7 access, personal training sessions, and spa facilities. We offer student and senior citizen discounts of 15% on all plans. Corporate partnerships are available for companies with 10+ employees joining.\",\n",
    "        metadata={\"source\": \"membership.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Group fitness classes at Peak Performance Gym include Yoga (beginner, intermediate, advanced), HIIT, Zumba, Spin Cycling, CrossFit, and Pilates. Beginner classes are held every Monday and Wednesday at 6:00 PM. Intermediate and advanced classes are scheduled throughout the week. The full schedule is available on our mobile app or at the reception desk.\",\n",
    "        metadata={\"source\": \"classes.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Personal trainers at Peak Performance Gym are all certified professionals with minimum 5 years of experience. Each new member receives a complimentary fitness assessment and one free session with a trainer. Our head trainer, Neha Kapoor, specializes in rehabilitation fitness and sports-specific training. Personal training sessions can be booked individually (₹800/session) or in packages of 10 (₹7,000) or 20 (₹13,000).\",\n",
    "        metadata={\"source\": \"trainers.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Peak Performance Gym's facilities include a cardio zone with 30+ machines, strength training area, functional fitness space, dedicated yoga studio, spin class room, swimming pool (25m), sauna and steam rooms, juice bar, and locker rooms with shower facilities. Our equipment is replaced or upgraded every 3 years to ensure members have access to the latest fitness technology.\",\n",
    "        metadata={\"source\": \"facilities.txt\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs = {\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b959da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model = \"gemini-2.5-flash\")\n",
    "template = \"\"\"Answer the question based on the following context and the Chathistory. Especially take the latest question into consideration:\n",
    "\n",
    "Chathistory: {history}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce64ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0962b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    documents : List[Document]\n",
    "    on_topic : str\n",
    "    rephrased_question : str\n",
    "    proceed_to_generate : bool\n",
    "    rephrase_count : int\n",
    "    question: HumanMessage\n",
    "\n",
    "class GradeQuestion(BaseModel):\n",
    "    score: str = Field(\n",
    "        description=\"Question is about the specified topics? If yes -> 'Yes' if not -> 'No'\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7324f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_rewriter(state: AgentState) :\n",
    "    print(f\"Entering question_rewiter with the following state: {state}\")\n",
    "\n",
    "    # reset state vareibles except messages and question\n",
    "    state[\"documents\"] = []\n",
    "    state[\"on_topic\"] = \"\"\n",
    "    state[\"rephrased_question\"] = \"\"\n",
    "    state[\"proceed_to_generate\"] = False\n",
    "    state[\"rephrase_count\"] = 0\n",
    "\n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        state[\"messages\"] = []\n",
    "\n",
    "    if state[\"question\"] not in state[\"messages\"]:\n",
    "        state[\"messages\"].append(state[\"question\"])\n",
    "\n",
    "    if len(state[\"messages\"]) >1 :\n",
    "        conversation = state[\"messages\"][:-1]\n",
    "        current_question = state[\"messages\"][-1].content\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=\"You are a helpful assistant that rephrases the user's question to be a standalone question optimized for retrieval.\"\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        messages.extend(conversation)\n",
    "        messages.append(HumanMessage(content=current_question))\n",
    "        rephrase_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        llm= ChatGoogleGenerativeAI(model = \"gemini-2.5-flash\")\n",
    "        prompt = rephrase_prompt.format()\n",
    "        response = llm.invoke(prompt)\n",
    "        better_question = response.content.strip()\n",
    "        state[\"rephrased_question\"] = better_question\n",
    "    else :\n",
    "        state[\"rephrased_question\"] = state[\"question\"].content\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8372e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_classifier(state: AgentState) :\n",
    "    print(\"Entering question_classifier\")\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\" You are a classifier that determines whether a user's question is about one of the following topics \n",
    "    \n",
    "    1. Gym History & Founder\n",
    "    2. Operating Hours\n",
    "    3. Membership Plans \n",
    "    4. Fitness Classes\n",
    "    5. Personal Trainers\n",
    "    6. Facilities & Equipment\n",
    "    7. Anything else about Peak Performance Gym\n",
    "    \n",
    "    If the question IS about any of these topics, respond with 'Yes'. Otherwise, respond with 'No'.\n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        system_message,\n",
    "        HumanMessage(\n",
    "            content=f\"Question: {state['rephrased_question']}.\"\n",
    "        ),\n",
    "    ]\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    structrued_llm = llm.with_structured_output(GradeQuestion)\n",
    "    grader_llm = grade_prompt | structrued_llm\n",
    "    result = grader_llm.invoke({})\n",
    "\n",
    "    state[\"on_topic\"] = result.score.strip()\n",
    "    print(f\"question_classifier: on_topic = {state['on_topic']}\")\n",
    "    return state\n",
    "\n",
    "def on_topic_router(state: AgentState):\n",
    "    print(\"Entering on_topic_router\")\n",
    "    on_topic = state.get(\"on_topic\", \"\").strip().lower()\n",
    "    if on_topic == \"yes\":\n",
    "        print(\"Routing to retrieve\")\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        print(\"Routing to off_topic_response\")\n",
    "        return \"off_topic_response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f294c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: AgentState):\n",
    "    print(\"Entering retrieve\")\n",
    "    question = state[\"rephrased_question\"]\n",
    "    docs = retriever.invoke(question)\n",
    "    state[\"documents\"] = docs\n",
    "    print(f\"Retrieved {len(docs)} documents.\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef133fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocument(BaseModel):\n",
    "    score: str = Field(\n",
    "        description=\"Document is relevant to the question? If yes -> 'Yes' if not -> 'No'\"\n",
    "    )\n",
    "\n",
    "def retriveval_relevance_checker(state: AgentState):\n",
    "    print(\"Entering retriveval_relevance_checker\")\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"You are a grader assessing the relevance of a retrieved document to a user question.\n",
    "                    Only answer with 'Yes' or 'No'.\n",
    "\n",
    "                    If the document contains information relevant to the user's question, respond with 'Yes'.\n",
    "                    Otherwise, respond with 'No'.\"\"\"\n",
    "    )\n",
    "\n",
    "    structured_llm = llm.with_structured_output(GradeDocument)\n",
    "\n",
    "    relevant_docs = []\n",
    "    for doc in state[\"documents\"]:\n",
    "        human_message = HumanMessage(\n",
    "            content=f\"User Question: {state['rephrased_question']}\\n\\nDocument: {doc.page_content}\"\n",
    "        )\n",
    "        grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "        grader_chain = grade_prompt | structured_llm\n",
    "        result = grader_chain.invoke({})\n",
    "        if result.score.strip().lower() == \"yes\":\n",
    "            relevant_docs.append(doc)\n",
    "\n",
    "    state[\"documents\"] = relevant_docs\n",
    "    state[\"proceed_to_generate\"] = len(relevant_docs) > 0\n",
    "    print(f\"Filtered to {len(relevant_docs)} relevant documents.\")\n",
    "    print(f\"proceed_to_generate set to {state['proceed_to_generate']}\")\n",
    "\n",
    "    return state\n",
    "\n",
    "def proceed_router(state: AgentState):\n",
    "    print(\"Entering proceed_router\")\n",
    "    rephrase_count = state.get(\"rephrase_count\", 0)\n",
    "    if state.get(\"proceed_to_generate\", False):\n",
    "        print(\"Routing to generate_answer\")\n",
    "        return \"generate_answer\"\n",
    "    elif rephrase_count >= 2:\n",
    "        print(\"Routing to no_relevant_docs_response\")\n",
    "        return \"cannot_answer\"\n",
    "    else:\n",
    "        print(\"Routing to refine_question\")\n",
    "        return \"refine_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f69a1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_question(state: AgentState):\n",
    "    print(\"Entering refine_question\")\n",
    "    rephrase_count = state.get(\"rephrase_count\", 0) \n",
    "    if rephrase_count >= 2:\n",
    "        print(\"Maximum rephrase attempts reached. Routing to cannot_answer.\")\n",
    "        return state\n",
    "    question_to_refine = state[\"rephrased_question\"]\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"You are a helpful assistant that slightly refines the user's question to improve retrieval results.\n",
    "Provide a slightly adjusted version of the question.\"\"\"\n",
    "    )\n",
    "    human_message = HumanMessage(\n",
    "        content=f\"Original question: {question_to_refine}\\n\\nProvide a slightly refined question.\"\n",
    "    )\n",
    "    refine_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    llm = ChatGoogleGenerativeAI(model = \"gemini-2.5-flash\")\n",
    "    prompt = refine_prompt.format()\n",
    "    response = llm.invoke(prompt)\n",
    "    refined_question = response.content.strip()\n",
    "    state[\"rephrased_question\"] = refined_question\n",
    "    state[\"rephrase_count\"] = rephrase_count + 1\n",
    "    print(f\"Refined question to: {refined_question}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07e1a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: AgentState):\n",
    "    print(\"Entering generate_answer\")\n",
    "    history = state[\"messages\"]\n",
    "    docs = state[\"documents\"]\n",
    "    rephrased_question = state[\"rephrased_question\"]\n",
    "\n",
    "    rag_input = {\n",
    "        \"history\": history,\n",
    "        \"context\": docs,\n",
    "        \"question\": rephrased_question\n",
    "    }\n",
    "\n",
    "    print(\"RAG Input prepared, invoking RAG chain...\")\n",
    "    response = rag_chain.invoke(rag_input)\n",
    "    generation = response.content.strip()\n",
    "    print(f\"Generated answer: {generation}\")\n",
    "    state[\"messages\"].append(AIMessage(content=generation))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce38714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannot_answer(state: AgentState):\n",
    "    print(\"Entering cannot_answer\")\n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        state[\"messages\"] = []\n",
    "    state[\"messages\"].append(\n",
    "        AIMessage(\n",
    "            content=\"I'm sorry, but I cannot find the information you're looking for.\"\n",
    "        )\n",
    "    )\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ed62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_topic_response(state: AgentState):\n",
    "    print(\"Entering off_topic_response\")\n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        state[\"messages\"] = []\n",
    "    state[\"messages\"].append(AIMessage(content=\"I'm sorry! I cannot answer this question!\"))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59e96454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6fb4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"question_rewriter\", question_rewriter)\n",
    "workflow.add_node(\"question_classifier\", question_classifier)\n",
    "workflow.add_node(\"off_topic_response\", off_topic_response)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"retriveval_relevance_checker\", retriveval_relevance_checker)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.add_node(\"refine_question\", refine_question)\n",
    "workflow.add_node(\"cannot_answer\", cannot_answer)\n",
    "\n",
    "workflow.add_edge(\"question_rewriter\", \"question_classifier\")\n",
    "workflow.add_conditional_edges(\"question_classifier\", on_topic_router)\n",
    "workflow.add_edge(\"retrieve\", \"retriveval_relevance_checker\")\n",
    "workflow.add_conditional_edges(\"retriveval_relevance_checker\", proceed_router)\n",
    "\n",
    "workflow.add_edge(\"refine_question\", \"retrieve\")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"cannot_answer\", END)\n",
    "workflow.add_edge(\"off_topic_response\", END)\n",
    "workflow.set_entry_point(\"question_rewriter\")\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc74937",
   "metadata": {},
   "source": [
    "#### Off_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a597e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewiter with the following state: {'question': HumanMessage(content='What does the company Apple do?', additional_kwargs={}, response_metadata={})}\n",
      "Entering question_classifier\n",
      "question_classifier: on_topic = No\n",
      "Entering on_topic_router\n",
      "Routing to off_topic_response\n",
      "Entering off_topic_response\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What does the company Apple do?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm sorry! I cannot answer this question!\", additional_kwargs={}, response_metadata={})],\n",
       " 'documents': [],\n",
       " 'on_topic': 'No',\n",
       " 'rephrased_question': 'What does the company Apple do?',\n",
       " 'proceed_to_generate': False,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content='What does the company Apple do?', additional_kwargs={}, response_metadata={})}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\"question\": HumanMessage(content=\"What does the company Apple do?\")}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2e5b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = {\n",
    "#     \"question\": HumanMessage(\n",
    "#         content=\"What is the cancelation policy for Peak Performance Gym memberships?\"\n",
    "#     )\n",
    "# }\n",
    "# graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 2}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "416dac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewiter with the following state: {'question': HumanMessage(content='Who founded Peak Performance Gym?', additional_kwargs={}, response_metadata={})}\n",
      "Entering question_classifier\n",
      "question_classifier: on_topic = Yes\n",
      "Entering on_topic_router\n",
      "Routing to retrieve\n",
      "Entering retrieve\n",
      "Retrieved 4 documents.\n",
      "Entering retriveval_relevance_checker\n",
      "Filtered to 1 relevant documents.\n",
      "proceed_to_generate set to True\n",
      "Entering proceed_router\n",
      "Routing to generate_answer\n",
      "Entering generate_answer\n",
      "RAG Input prepared, invoking RAG chain...\n",
      "Generated answer: Marcus Chen founded Peak Performance Gym.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Who founded Peak Performance Gym?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Marcus Chen founded Peak Performance Gym.', additional_kwargs={}, response_metadata={})],\n",
       " 'documents': [Document(metadata={'source': 'about.txt'}, page_content='Peak Performance Gym was founded in 2015 by former Olympic athlete Marcus Chen. With over 15 years of experience in professional athletics, Marcus established the gym to provide personalized fitness solutions for people of all levels. The gym spans 10,000 square feet and features state-of-the-art equipment.')],\n",
       " 'on_topic': 'Yes',\n",
       " 'rephrased_question': 'Who founded Peak Performance Gym?',\n",
       " 'proceed_to_generate': True,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content='Who founded Peak Performance Gym?', additional_kwargs={}, response_metadata={})}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"question\": HumanMessage(content=\"Who founded Peak Performance Gym?\")\n",
    "}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "633c28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = {\"question\": HumanMessage(content=\"When did he start it?\")}\n",
    "# graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09facbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
